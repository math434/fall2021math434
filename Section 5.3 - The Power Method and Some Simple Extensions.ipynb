{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "together-disability",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 5.3: The Power Method and Some Simple Extensions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-murder",
   "metadata": {},
   "source": [
    "Let $A \\in \\mathbb{C}^{n \\times n}$ be a matrix with _linearly independent_ eigenvectors\n",
    "\n",
    "$$\n",
    "v_1, \\ldots, v_n\n",
    "$$\n",
    "\n",
    "and corresponding eigenvalues\n",
    "\n",
    "$$\n",
    "\\lambda_1, \\ldots, \\lambda_n\n",
    "$$\n",
    "\n",
    "(i.e., $A v_i = \\lambda_i v_i$, for $i=1,\\ldots,n$) ordered such that\n",
    "\n",
    "$$\n",
    "|\\lambda_1| \\ge |\\lambda_2| \\ge \\cdots \\ge |\\lambda_n|.\n",
    "$$\n",
    "\n",
    "We say that $A$ has a **dominant eigenvalue** if\n",
    " \n",
    "$$\n",
    "|\\lambda_1| > |\\lambda_2|.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-philosophy",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-insight",
   "metadata": {},
   "source": [
    "## The Power Method\n",
    "\n",
    "The basic idea of the **power method** is to pick a vector $q \\in \\mathbb{C}^n$ and compute the sequence\n",
    "\n",
    "$$\n",
    "q,\\ A q,\\ A^2 q,\\ A^3 q,\\ \\ldots.\n",
    "$$\n",
    "\n",
    "Since the eigenvectors $v_1,\\ldots,v_n$ form a basis for $\\mathbb{C}^n$, we have that\n",
    "\n",
    "$$\n",
    "q = c_1 v_1 + \\cdots + c_n v_n.\n",
    "$$\n",
    "\n",
    "For a random $q$, we expect $c_1 \\ne 0$.\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "A q\n",
    "&= c_1 A v_1 + \\cdots + c_n A v_n \\\\\n",
    "&= c_1 \\lambda_1 v_1 + \\cdots + c_n \\lambda_n v_n\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "A^2 q\n",
    "&= c_1 \\lambda_1 A v_1 + \\cdots + c_n \\lambda_n A v_n \\\\\n",
    "&= c_1 \\lambda_1^2 v_1 + \\cdots + c_n \\lambda_n^2 v_n.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In general, we have\n",
    "\n",
    "$$\n",
    "A^j q = c_1 \\lambda_1^j v_1 + \\cdots + c_n \\lambda_n^j v_n\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\frac{A^j q}{\\lambda_1^j} = c_1 v_1 + c_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^j v_2 + \\cdots + c_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^j v_n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-affect",
   "metadata": {},
   "source": [
    "Letting\n",
    "\n",
    "$$\n",
    "q_j = \\frac{A^j q}{\\lambda_1^j},\n",
    "$$\n",
    "\n",
    "we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\| q_j - c_1 v_1 \\|\n",
    "&= \\left\\| c_2 \\left(\\frac{\\lambda_2}{\\lambda_1}\\right)^j v_2 + \\cdots + c_n \\left(\\frac{\\lambda_n}{\\lambda_1}\\right)^j v_n \\right\\| \\\\\n",
    "&\\le |c_2| \\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^j \\|v_2\\| + \\cdots + |c_n| \\left|\\frac{\\lambda_n}{\\lambda_1}\\right|^j \\|v_n\\| \\\\\n",
    "&\\le \\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^j \\big(|c_2| \\|v_2\\| + \\cdots + |c_n| \\|v_n\\|\\big).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now suppose $|\\lambda_1| > |\\lambda_2|$. Then\n",
    "\n",
    "$$\n",
    "\\left|\\frac{\\lambda_2}{\\lambda_1}\\right| < 1.\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\left|\\frac{\\lambda_2}{\\lambda_1}\\right|^j \\to 0 \\quad \\text{as} \\ j \\to \\infty.\n",
    "$$\n",
    "\n",
    "Thus, $\\| q_j - c_1 v_1 \\| \\to 0$ as $j \\to \\infty$, so we conclude that\n",
    "\n",
    "$$\n",
    "q_j \\to c_1 v_1 \\quad \\text{as $j \\to \\infty$.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-novel",
   "metadata": {},
   "source": [
    "The rate of the convergence of the power method is generally linear ($\\|q_{j+1} - c_1 v_1\\| \\approx r \\|q_j - c_1 v_1\\|$ for all $j$ sufficiently large) with convergence ratio\n",
    "\n",
    "$$\n",
    "r = \\left|\\frac{\\lambda_2}{\\lambda_1}\\right|.\n",
    "$$\n",
    "\n",
    "Thus, the larger the gap between $|\\lambda_1|$ and $|\\lambda_2|$, the smaller the convergence ratio and the faster the convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-reader",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-wright",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "\n",
    "Since we usually do not know $\\lambda_1$ while running the power method, we will not be able to compute $q_j = A^j q/\\lambda_1^j$. However, it is important that we scale $A^j q$ since $\\|A^j q\\| \\to \\infty$ if $|\\lambda_1| > 1$ and $\\|A^j q\\| \\to 0$ if $|\\lambda_1| < 1$.\n",
    "\n",
    "A simple choice is to scale $A^j q$ so that its largest entry is equal to one. Thus, we let\n",
    "\n",
    "$$\n",
    "q_{j+1} = \\frac{A q_j}{s_{j+1}},\n",
    "$$\n",
    "\n",
    "where $s_{j+1}$ is the component of $A q_j$ which has the largest absolute value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-engagement",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-column",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "Given $q_0 \\in \\mathbb{C}^n$, we iterate\n",
    "\n",
    "1. $\\hat{q} = A q_j$\n",
    "\n",
    "2. $s_{j+1} =$ entry of $\\hat{q}$ with largest absolute value\n",
    "\n",
    "3. $q_{j+1} \\gets \\hat{q}/s_{j+1}$\n",
    "\n",
    "for $j = 0, 1, 2, \\ldots$.\n",
    "\n",
    "Then $q_j$ approaches a multiple of $v_1$ and $s_j$ approaches the eigenvalue $\\lambda_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-convertible",
   "metadata": {},
   "source": [
    "If $A$ is a dense $n \\times n$ matrix, then each iteration of this algorithm will require $2n^2 + O(n)$ flops. However, if $A$ is sparse and has at most $k$ nonzeros on each row, then each iteration will require approximately $2 k n$ flops. Therefore, the power method is very well suited for computing the dominant eigenvalue and associated eigenvector of large sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-imperial",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-fighter",
   "metadata": {},
   "source": [
    "## `power_method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, SparseArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "function scale!(q)\n",
    "    maxval, idx = maximum((abs(q[i]),i) for i=1:length(q))\n",
    "    s = q[idx]\n",
    "    q ./= s\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "function power_method(A; tol=sqrt(eps())/2, maxiter=100_000)\n",
    "    m, n = size(A)\n",
    "    n == m || error(\"Matrix must be square.\")\n",
    "    \n",
    "    q = randn(n)\n",
    "    s = scale!(q)\n",
    "\n",
    "    qold = similar(q)\n",
    "    tmp = similar(q)\n",
    "\n",
    "    k = 0\n",
    "    done = false\n",
    "    while !done && k < maxiter\n",
    "        k += 1\n",
    "        copy!(qold, q)        # qold = q\n",
    "        mul!(q, A, qold)      # q = A*qold\n",
    "        s = scale!(q)         # q = q/s\n",
    "        tmp .= q .- qold\n",
    "        done = norm(tmp)/(norm(q) + 1) <= tol\n",
    "    end\n",
    "\n",
    "    if done\n",
    "        println(\"Converged after $k iterations.\")\n",
    "    else\n",
    "        println(\"Failed to converge.\")\n",
    "    end\n",
    "\n",
    "    return s, q\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "k = 10\n",
    "density = (k - 1)/n    # density = (k*n - n)/n^2\n",
    "\n",
    "A = triu(sprand(n, n, density), 1)\n",
    "A = A + A' + I\n",
    "\n",
    "# Expect nnz(A) ≈ k*n\n",
    "@show nnz(A)\n",
    "\n",
    "if n <= 1000\n",
    "    λ = eigvals(Matrix(A))\n",
    "    abseig = abs.(λ) |> sort\n",
    "    r = abseig[end-1]/abseig[end]\n",
    "    @show r\n",
    "end\n",
    "\n",
    "@time s, q = power_method(A)\n",
    "\n",
    "@show norm(A*q - s*q);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-chance",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-sympathy",
   "metadata": {},
   "source": [
    "## Google PageRank Algorithm\n",
    "\n",
    "Google uses its [PageRank](https://en.wikipedia.org/wiki/PageRank) algorithm to determine its ranking of webpages in search results.\n",
    "\n",
    "The [Google matrix](https://en.wikipedia.org/wiki/Google_matrix) represents how webpages on the Internet link to one another.\n",
    "\n",
    "PageRank uses the power method to compute the dominant eigenvector of the Google matrix, and this dominant eigenvector is then used to rank the importance of webpages.\n",
    "\n",
    "By design, the convergence ratio of the Google matrix is\n",
    "\n",
    "$$\n",
    "\\left|\\frac{\\lambda_2}{\\lambda_1}\\right| = 0.85,\n",
    "$$\n",
    "\n",
    "so the number of power method iterations is reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-concentrate",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-indication",
   "metadata": {},
   "source": [
    "## The Inverse Power Method\n",
    "\n",
    "Let $A \\in \\mathbb{C}^{n \\times n}$ be nonsingular. Since $A$ is nonsingular, all of its eigenvalues are nonzero. \n",
    "\n",
    "Since\n",
    "\n",
    "$$\n",
    "A v = \\lambda v \\quad \\implies \\quad A^{-1} v = \\lambda^{-1} v,\n",
    "$$\n",
    "\n",
    "the eigenvalues of $A^{-1}$ are $\\lambda_1^{-1},\\ldots,\\lambda_n^{-1}$ and the corresponding eigenvectors are $v_1,\\ldots,v_n$.\n",
    "\n",
    "Since\n",
    "\n",
    "$$\n",
    "|\\lambda_1| \\ge |\\lambda_2| \\ge \\cdots \\ge |\\lambda_n|,\n",
    "$$\n",
    "\n",
    "we have that\n",
    "\n",
    "$$\n",
    "\\left|\\lambda_1^{-1}\\right| \\le \\left|\\lambda_2^{-1}\\right| \\le \\cdots \\le \\left|\\lambda_n^{-1}\\right|.\n",
    "$$\n",
    "\n",
    "If $|\\lambda_{n-1}| > |\\lambda_n|$, then $\\left|\\lambda_n^{-1}\\right| >  \\left|\\lambda_{n-1}^{-1}\\right|$, so the **inverse power method**,\n",
    "\n",
    "$$\n",
    "q,\\ A^{-1} q,\\ A^{-2} q,\\ A^{-3} q,\\ \\ldots,\n",
    "$$\n",
    "\n",
    "will generate a sequence $q_j$ that converges to a multiple of $v_n$ (i.e., the eigenvector corresponding to the _smallest_ eigenvalue of $A$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-dover",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-thriller",
   "metadata": {},
   "source": [
    "## `inverse_power_method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "function inverse_power_method(A; tol=sqrt(eps())/2, maxiter=100_000)\n",
    "    m, n = size(A)\n",
    "    n == m || error(\"Matrix must be square.\")\n",
    "    \n",
    "    F = lu(A)\n",
    "    \n",
    "    q = randn(n)\n",
    "    s = scale!(q)\n",
    "\n",
    "    qold = similar(q)\n",
    "    tmp = similar(q)\n",
    "\n",
    "    k = 0\n",
    "    done = false\n",
    "    while !done && k < maxiter\n",
    "        k += 1\n",
    "        copy!(qold, q)        # qold = q\n",
    "        ldiv!(q, F, qold)     # q = F\\qold\n",
    "        s = scale!(q)         # q = q/s\n",
    "        tmp .= q .- qold\n",
    "        done = norm(tmp)/(norm(q) + 1) <= tol\n",
    "    end\n",
    "\n",
    "    if done\n",
    "        println(\"Converged after $k iterations.\")\n",
    "    else\n",
    "        println(\"Failed to converge.\")\n",
    "    end\n",
    "\n",
    "    return 1/s, q\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "k = 5\n",
    "density = (k - 1)/n    # density = (k*n - n)/n^2\n",
    "\n",
    "A = triu(sprand(n, n, density), 1)\n",
    "A = A + A' + I\n",
    "\n",
    "# Expect nnz(A) ≈ k*n\n",
    "@show nnz(A)\n",
    "\n",
    "if n <= 1000\n",
    "    λ = eigvals(Matrix(A))\n",
    "    abseig = abs.(λ) |> sort\n",
    "    r = abseig[1]/abseig[2]\n",
    "    @show r\n",
    "end\n",
    "\n",
    "@time s, q = inverse_power_method(A)\n",
    "\n",
    "@show norm(A*q - s*q);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-tackle",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-massage",
   "metadata": {},
   "source": [
    "## The Shift-and-Invert Method\n",
    "\n",
    "If $A v = \\lambda v$, then\n",
    "\n",
    "$$\n",
    "\\big( A - \\rho I \\big) v = \\big( \\lambda - \\rho \\big) v.\n",
    "$$\n",
    "\n",
    "Therefore, using the inverse power method on $A - \\rho I$, we can compute an eigenvector with eigenvalue closest to the shift $\\rho$.\n",
    "\n",
    "That is, if\n",
    "\n",
    "$$\n",
    "|\\lambda_i - \\rho| \\gg |\\lambda_j - \\rho|, \\quad \\forall j \\ne i,\n",
    "$$\n",
    "\n",
    "then the **shift-and-invert method**,\n",
    "\n",
    "$$\n",
    "q,\\ (A - \\rho I)^{-1} q,\\ (A - \\rho I)^{-2} q,\\ (A - \\rho I)^{-3} q,\\ \\ldots,\n",
    "$$\n",
    "\n",
    "will generate a sequence $q_j$ that converges to a multiple of $v_i$.\n",
    "\n",
    "The rate of convergence is\n",
    "\n",
    "$$\n",
    "\\left| \\frac{\\lambda_i - \\rho}{\\lambda_k - \\rho} \\right|,\n",
    "$$\n",
    "\n",
    "where $\\lambda_k - \\rho$ is the second smallest eigenvalue of $A - \\rho I$ in absolute value.\n",
    "\n",
    "Once we have an $LU$ decomposition of $A - \\rho I$ (which requires $\\frac{2}{3}n^3 + O(n^2)$ flops), we can compute\n",
    "\n",
    "$$\n",
    "q \\gets (A - \\rho I)^{-1} q\n",
    "$$\n",
    "\n",
    "each iteration in $2 n^2$ flops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-currency",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-zealand",
   "metadata": {},
   "source": [
    "## `inverse_power_method` with shift $\\rho$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "function inverse_power_method(A; ρ=0.0, tol=sqrt(eps())/2, maxiter=100_000)\n",
    "    m, n = size(A)\n",
    "    n == m || error(\"Matrix must be square.\")\n",
    "    \n",
    "    F = lu(A - ρ*I)\n",
    "    \n",
    "    q = randn(n)\n",
    "    s = scale!(q)\n",
    "\n",
    "    qold = similar(q)\n",
    "    tmp = similar(q)\n",
    "\n",
    "    k = 0\n",
    "    done = false\n",
    "    while !done && k < maxiter\n",
    "        k += 1\n",
    "        copy!(qold, q)        # qold = q\n",
    "        ldiv!(q, F, qold)     # q = F\\qold\n",
    "        s = scale!(q)         # q = q/s\n",
    "        tmp .= q .- qold\n",
    "        done = norm(tmp)/(norm(q) + 1) <= tol\n",
    "    end\n",
    "\n",
    "    if done\n",
    "        println(\"Converged after $k iterations.\")\n",
    "    else\n",
    "        println(\"Failed to converge.\")\n",
    "    end\n",
    "\n",
    "    return 1/s + ρ, q\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000\n",
    "k = 5\n",
    "density = (k - 1)/n    # density = (k*n - n)/n^2\n",
    "\n",
    "A = triu(sprand(n, n, density), 1)\n",
    "A = A + A' + I\n",
    "\n",
    "ρ = 2.0\n",
    "\n",
    "# Expect nnz(A) ≈ k*n\n",
    "@show nnz(A)\n",
    "\n",
    "if n <= 1000\n",
    "    λ = eigvals(Matrix(A))\n",
    "    abseig = abs.(λ .- ρ) |> sort\n",
    "    r = abseig[1]/abseig[2]\n",
    "    @show r\n",
    "end\n",
    "\n",
    "@time s, q = inverse_power_method(A, ρ=ρ)\n",
    "\n",
    "@show ρ, s\n",
    "\n",
    "@show norm(A*q - s*q);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-visiting",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-chamber",
   "metadata": {},
   "source": [
    "## Rayleigh Quotient Iteration\n",
    "\n",
    "Suppose $q \\in \\mathbb{C}^n$ approximates an eigenvalue of $A$. If $A q = \\rho q$, then $\\rho$ is an eigenvalue of $A$. Otherwise, we want to find the value of $\\rho$ that minimizes\n",
    "\n",
    "$$\n",
    "\\| A q - \\rho q \\|_2.\n",
    "$$\n",
    "\n",
    "The _normal equations_ for this least squares problem is\n",
    "\n",
    "$$\n",
    "(q^* q) \\rho = q^* A q,\n",
    "$$\n",
    "\n",
    "where $q^*$ is the **conjugate transpose** of $q$.\n",
    "\n",
    "For example, if\n",
    "\n",
    "$$\n",
    "q = \\begin{bmatrix} 1 + 3 i \\\\ 4 - 2 i \\end{bmatrix},\n",
    "$$\n",
    "\n",
    "then\n",
    "\n",
    "$$\n",
    "q^* = \\begin{bmatrix} 1 - 3 i & 4 + 2 i \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Note that $q^* q = \\|q\\|_2^2$.\n",
    "\n",
    "The solution of the normal equations is\n",
    "\n",
    "$$\n",
    "\\rho = \\frac{q^* A q}{q^* q}\n",
    "$$\n",
    "\n",
    "and is called the **Rayleigh quotient**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-playlist",
   "metadata": {},
   "source": [
    "The **Rayleigh quotient iteration** uses\n",
    "\n",
    "$$\n",
    "\\rho_j = \\frac{q_j^* A q_j}{q_j^* q_j}\n",
    "$$\n",
    "\n",
    "as the _shift_ in each iteration of the inverse power method.\n",
    "\n",
    "Since the shift changes each iteration, we need to compute an $LU$ decomposition _each iteration_. This can be very expensive since each iteration will now cost $\\frac{2}{3}n^3 + O(n^2)$ flops.\n",
    "\n",
    "To make the Raleigh quotient iteration practical, we can first compute a \"simple\" matrix $H$ that is _similar_ to $A$, such as an **upper Hessenberg** matrix\n",
    "\n",
    "$$\n",
    "H =\n",
    "\\begin{bmatrix}\n",
    "* & * & * & * & * \\\\\n",
    "* & * & * & * & * \\\\\n",
    "  & * & * & * & * \\\\\n",
    "  &   & * & * & * \\\\\n",
    "  &   &   & * & * \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "or a **tridiagonal** matrix\n",
    "\n",
    "$$\n",
    "H =\n",
    "\\begin{bmatrix}\n",
    "* & * &   &   &   \\\\\n",
    "* & * & * &   &   \\\\\n",
    "  & * & * & * &   \\\\\n",
    "  &   & * & * & * \\\\\n",
    "  &   &   & * & * \\\\\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Computing $LU$ decomposition of an upper Hessenberg matrix only needs $O(n^2)$ flops, and the same for a tridiagonal matrix only needs $O(n)$ flops. We will return to this topic in Section 5.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-european",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-african",
   "metadata": {},
   "source": [
    "## Quadratic convergence of the Raleigh Quotient Iteration\n",
    "\n",
    "> ### Theorem: (Raleigh Quotient Approximates Eigenvalue)\n",
    ">\n",
    "> Let $A \\in \\mathbb{C}^{n \\times n}$. Let $v$ be an eigenvector of $A$ with eigenvalue $\\lambda$, and $\\|v\\|_2 = 1$.\n",
    ">\n",
    "> Let $q \\in \\mathbb{C}^n$ with $\\|q\\|_2 = 1$ and\n",
    ">\n",
    "> $$ \\rho = q^* A q $$\n",
    ">\n",
    "> be the Raleigh quotient of $q$. Then\n",
    ">\n",
    "> $$ |\\lambda - \\rho| \\le 2 \\|A\\|_2 \\|v - q\\|_2. $$\n",
    "\n",
    "Therefore, if $\\|v - q\\|_2 = O(\\varepsilon)$, then $|\\lambda - \\rho| = O(\\varepsilon)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-bloom",
   "metadata": {},
   "source": [
    "Let $q_0 \\in \\mathbb{C}^n$ such that $\\|q_0\\|_2 = 1$, and let $q_j$, for $j=1,2,\\ldots$, be defined by\n",
    "\n",
    "$$\n",
    "\\rho_j = q_j^* A q_j,\n",
    "\\qquad\n",
    "(A - \\rho_j I) \\hat{q}_{j+1} = q_j,\n",
    "\\qquad\n",
    "q_{j+1} = \\hat{q}_{j+1}/\\|\\hat{q}_{j+1}\\|_2.\n",
    "$$\n",
    "\n",
    "Then $\\|q_j\\|_2 = 1$, for all $j$.\n",
    "\n",
    "1. Suppose that $q_j \\to v_i$ as $j \\to \\infty$. Then $\\|v_i\\|_2 = 1$ and $\\rho_j \\to \\lambda_i$ as $j \\to \\infty$.\n",
    "\n",
    "2. Let $\\lambda_k$ be the closest eigenvalue to $\\lambda_i$.\n",
    "\n",
    "3. Suppose that $\\rho_j \\approx \\lambda_i$.\n",
    "\n",
    "Then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\|v_i - q_{j+1}\\|_2\n",
    "&\\approx \\left| \\frac{(\\lambda_k - \\rho_j)^{-1}}{(\\lambda_i - \\rho_j)^{-1}} \\right| \\|v_i - q_j\\|_2 \\\\\n",
    "&= \\left| \\frac{\\lambda_i - \\rho_j}{\\lambda_k - \\rho_j} \\right| \\|v_i - q_j\\|_2 \\\\\n",
    "&\\le \\frac{2 \\|A\\|_2 \\|v_i - q_j\\|_2}{|\\lambda_k - \\rho_j|} \\|v_i - q_j\\|_2 \\\\\n",
    "&\\approx \\frac{2 \\|A\\|_2}{|\\lambda_k - \\lambda_i|} \\|v_i - q_j\\|_2^2. \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Thus, we obtain the estimate\n",
    "\n",
    "$$ \\|v_i - q_{j+1}\\|_2 \\approx C \\|v_i - q_j\\|_2^2, $$\n",
    "\n",
    "where $C = 2 \\|A\\|_2 / |\\lambda_k - \\lambda_i|$. This indicates that the Rayleigh quotient iteration typically converges _quadratically_ when it does converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-insider",
   "metadata": {},
   "source": [
    "Moreover, if $A$ is a symmetric matrix, then $\\|v - q\\|_2 = O(\\varepsilon)$ implies that $|\\lambda - \\rho| = O(\\varepsilon^2)$, which indicates _cubic_ convergence:\n",
    "\n",
    "$$ \\|v_i - q_{j+1}\\|_2 \\approx C \\|v_i - q_j\\|_2^3. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-boundary",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
